{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: appdirs==1.4.4 in c:\\users\\anany\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 2)) (1.4.4)\n",
      "Collecting astor==0.8.0\n",
      "  Using cached astor-0.8.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting backcall==0.2.0\n",
      "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting beautifulsoup4==4.9.1\n",
      "  Using cached beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n",
      "Collecting blinker==1.4\n",
      "  Using cached blinker-1.4.tar.gz (111 kB)\n",
      "Collecting brotlipy==0.7.0\n",
      "  Using cached brotlipy-0.7.0-cp37-cp37m-win_amd64.whl (372 kB)\n",
      "Processing c:\\users\\anany\\appdata\\local\\pip\\cache\\wheels\\0a\\9e\\ba\\20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\\bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: cachetools@ file:///tmp/build/80754af9/cachetools_1596822027882/work from file:///tmp/build/80754af9/cachetools_1596822027882/work in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (4.1.0)\n",
      "Requirement already satisfied: certifi==2020.6.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (2020.6.20)\n",
      "Requirement already satisfied: cffi==1.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: chardet==3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (3.0.4)\n",
      "Collecting click==7.1.2\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: colorama==0.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 14)) (0.4.3)\n",
      "Collecting cryptography==2.9.2\n",
      "  Using cached cryptography-2.9.2-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 16)) (0.10.0)\n",
      "Collecting decorator==4.4.2\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: distlib==0.3.0 in c:\\users\\anany\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 18)) (0.3.0)\n",
      "Requirement already satisfied: filelock==3.0.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 19)) (3.0.12)\n",
      "Collecting gast==0.2.2\n",
      "  Using cached gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: google-auth@ file:///tmp/build/80754af9/google-auth_1596863485713/work from file:///tmp/build/80754af9/google-auth_1596863485713/work in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 21)) (1.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 22)) (0.4.1)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 23)) (0.2.0)\n",
      "Collecting grpcio==1.27.2\n",
      "  Using cached grpcio-1.27.2-cp37-cp37m-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: h5py==2.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 25)) (2.10.0)\n",
      "Requirement already satisfied: idna@ file:///tmp/build/80754af9/idna_1593446292537/work from file:///tmp/build/80754af9/idna_1593446292537/work in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 26)) (2.8)\n",
      "Collecting importlib-metadata==1.7.0\n",
      "  Using cached importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: ipython@ file:///C:/ci/ipython_1596868620883/work from file:///C:/ci/ipython_1596868620883/work in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 28)) (7.12.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 29)) (0.2.0)\n",
      "Requirement already satisfied: jedi@ file:///C:/ci/jedi_1596472767194/work from file:///C:/ci/jedi_1596472767194/work in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 30)) (0.14.1)\n",
      "Requirement already satisfied: joblib@ file:///tmp/build/80754af9/joblib_1594236160679/work from file:///tmp/build/80754af9/joblib_1594236160679/work in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 31)) (0.16.0)\n",
      "Processing c:\\tmp\\build\\80754af9\\keras-applications_1594366238411\\work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\\\tmp\\\\build\\\\80754af9\\\\keras-applications_1594366238411\\\\work'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my gereneral imports\n",
    "import os\n",
    "import wget\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "# url data reader imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Scikit-Learn imports\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TensorFlow â‰¥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT = \"Bank\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\", PROJECT)\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "OUT_PATH = os.path.join(PROJECT_ROOT_DIR, \"output\", PROJECT)\n",
    "os.makedirs(OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Modelling Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build 2 binary classification models using any 2 of the following methods (in R or Python):\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. GBM\n",
    "4. Xgboost\n",
    "5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 579043 / 579043"
     ]
    }
   ],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00222/\"\n",
    "ext = 'zip'\n",
    "\n",
    "def list_files(url, ext=''):\n",
    "    page = requests.get(url).text\n",
    "#     print(page)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "\n",
    "for fileurl in list_files(url, ext):\n",
    "#     print(fileurl)\n",
    "    filename = fileurl.split('/')[-1]\n",
    "#     print(filename)\n",
    "    wget.download(fileurl, out=os.path.join(DATA_PATH, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bank-additional.zip', 'bank.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Read the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the data states that there are four datasets.\n",
    "We need\n",
    "> (1) `bank-additional-full.csv` with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014].[<sup>1</sup>](#fn1)\n",
    "\n",
    "An examination of the archive `bank-additional.zip` shows that it contains a folder called `bank-additional` with the files we need.\n",
    "\n",
    "<span id=\"fn1\"><sup>1</sup>\n",
    "    S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_file = ZipFile(os.path.join(DATA_PATH, 'bank-additional.zip'))\n",
    "df = pd.read_csv(\n",
    "    zip_file.open('bank-additional/bank-additional-full.csv'),\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Variable and Data Set Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define output variable and split the data into train, dev, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     36548\n",
      "yes     4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "X = df.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41188\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the target variable is *yes* for approximately 11% of cases. If we simply split the data into 80-10-10% train/val/test sets, there is a high chance that we end up with a lot of negative examples in the dev and test sets. This, in turn, might bias our evaluation of model performance.\n",
    "\n",
    "So, there are two options, I think:\n",
    "1. to use stratified shuffling to ensure that the proportions of positive and negative examples are similar in the split data sets, or\n",
    "2. use the test set from the website:\n",
    "    > (2) `bank-additional.csv` with 10% of the examples (4119), randomly selected from (1), and 20 inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would personally prefer option 1.\n",
    "But for the sake of completeness, let's see what distribution of the target variable is in the test file from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     3668\n",
      "yes     451\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test_web = pd.read_csv(\n",
    "    zip_file.open('bank-additional/bank-additional.csv'),\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    ")\n",
    "print(df_test_web['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear now, that the file on the website was generated using stratified shuffling.\n",
    "\n",
    "**Note:** In the PySpark exercise, the data was also split into train and test set. However, in this exercise, we are explicitly told that the test data is a subsample of the full data set.\n",
    "\n",
    "Therefore, I will use stratified shuffling to split the data into train/dev/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I put this import into the Setup section at the beginning\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     3655\n",
       "yes     464\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     32893\n",
       "yes     4176\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, stratify=y_trainval, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each of the train, dev, and test sets have roughly 11% of the positive outcomes.\n",
    "\n",
    "**Note:** such splitting method ensures that we avoid data mismatch problem, i.e. make our dev and test sets come from similar distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert our dependent variables in all the sets into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yesno_dict = {'yes': 1, 'no': 0}\n",
    "# y_trainval = y_trainval.map(yesno_dict).astype('int32')\n",
    "# y_train = y_train.map(yesno_dict).astype('int32')\n",
    "# y_val = y_val.map(yesno_dict).astype('int32')\n",
    "# y_test = y_test.map(yesno_dict).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an alternative way to transform labels:\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_trainval = le.fit_transform(y_trainval.astype(str))\n",
    "y_train = le.transform(y_train.astype(str))\n",
    "y_val = le.transform(y_val.astype(str))\n",
    "y_test = le.transform(y_test.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first explore the data to see what variables are continuous, what are needed to be categorized, and what are to be transformed into dummy variables (one-hot encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33362 entries, 22373 to 31364\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             33362 non-null  int64  \n",
      " 1   job             33362 non-null  object \n",
      " 2   marital         33362 non-null  object \n",
      " 3   education       33362 non-null  object \n",
      " 4   default         33362 non-null  object \n",
      " 5   housing         33362 non-null  object \n",
      " 6   loan            33362 non-null  object \n",
      " 7   contact         33362 non-null  object \n",
      " 8   month           33362 non-null  object \n",
      " 9   day_of_week     33362 non-null  object \n",
      " 10  duration        33362 non-null  int64  \n",
      " 11  campaign        33362 non-null  int64  \n",
      " 12  pdays           33362 non-null  int64  \n",
      " 13  previous        33362 non-null  int64  \n",
      " 14  poutcome        33362 non-null  object \n",
      " 15  emp.var.rate    33362 non-null  float64\n",
      " 16  cons.price.idx  33362 non-null  float64\n",
      " 17  cons.conf.idx   33362 non-null  float64\n",
      " 18  euribor3m       33362 non-null  float64\n",
      " 19  nr.employed     33362 non-null  float64\n",
      "dtypes: float64(5), int64(5), object(10)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the following variables are categorical (or binary):\n",
    "* job,\n",
    "* marital,\n",
    "* education,\n",
    "* housing,\n",
    "* loan,\n",
    "* contact,\n",
    "* month,\n",
    "* day_of_week,\n",
    "* poutcome.\n",
    "\n",
    "Let's check what values they take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n",
      "admin.           8415\n",
      "blue-collar      7510\n",
      "technician       5443\n",
      "services         3227\n",
      "management       2386\n",
      "retired          1383\n",
      "entrepreneur     1187\n",
      "self-employed    1142\n",
      "housemaid         867\n",
      "unemployed        823\n",
      "student           720\n",
      "unknown           259\n",
      "Name: job, dtype: int64\n",
      "\n",
      "\n",
      "marital\n",
      "married     20220\n",
      "single       9357\n",
      "divorced     3721\n",
      "unknown        64\n",
      "Name: marital, dtype: int64\n",
      "\n",
      "\n",
      "education\n",
      "university.degree      9845\n",
      "high.school            7711\n",
      "basic.9y               4887\n",
      "professional.course    4231\n",
      "basic.4y               3372\n",
      "basic.6y               1869\n",
      "unknown                1430\n",
      "illiterate               17\n",
      "Name: education, dtype: int64\n",
      "\n",
      "\n",
      "default\n",
      "no         26415\n",
      "unknown     6944\n",
      "yes            3\n",
      "Name: default, dtype: int64\n",
      "\n",
      "\n",
      "housing\n",
      "yes        17503\n",
      "no         15040\n",
      "unknown      819\n",
      "Name: housing, dtype: int64\n",
      "\n",
      "\n",
      "loan\n",
      "no         27452\n",
      "yes         5091\n",
      "unknown      819\n",
      "Name: loan, dtype: int64\n",
      "\n",
      "\n",
      "contact\n",
      "cellular     21145\n",
      "telephone    12217\n",
      "Name: contact, dtype: int64\n",
      "\n",
      "\n",
      "month\n",
      "may    11266\n",
      "jul     5826\n",
      "aug     4970\n",
      "jun     4263\n",
      "nov     3311\n",
      "apr     2108\n",
      "oct      562\n",
      "sep      462\n",
      "mar      450\n",
      "dec      144\n",
      "Name: month, dtype: int64\n",
      "\n",
      "\n",
      "day_of_week\n",
      "thu    6964\n",
      "mon    6889\n",
      "wed    6578\n",
      "tue    6549\n",
      "fri    6382\n",
      "Name: day_of_week, dtype: int64\n",
      "\n",
      "\n",
      "poutcome\n",
      "nonexistent    28800\n",
      "failure         3469\n",
      "success         1093\n",
      "Name: poutcome, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.select_dtypes(exclude=['int64', 'float64']).columns:\n",
    "    print(col)\n",
    "    print(X_train[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'poutcome'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of columns to be transformed from string to categorical numeric objects\n",
    "str_cat_vars = X_train.select_dtypes(exclude=['int64', 'float64']).columns.values\n",
    "str_cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
       "       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of numeric columns to be scaled\n",
    "num_vars = X_train.select_dtypes(include=['int64', 'float64']).columns.values\n",
    "num_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The description of the data says:\n",
    "> DURATION: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "Following this recommendation, I exclude the duration variable from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    num_vars = np.setdiff1d(num_vars, ['duration'])\n",
    "except ValueError:\n",
    "    print(\"`num_vars` does not contain 'duration'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Declare the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want the following steps to be processed in my preprocessing pipeline.\n",
    "1. Transform text variables into categorical numeric;\n",
    "2. Transform categorical variables into a set of binary variables (dummies, or one-hot encoded);\n",
    "3. Standardize continuous variables.\n",
    "\n",
    "**Note:** I treat variables of type `int64` as continuous. Sometimes, we want to treat such variables as categorical variables, so we then transform them into a set of dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I put these imports into the Setup section at the beginning\n",
    "# from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# encoder = OrdinalEncoder()\n",
    "# dummies = OneHotEncoder()\n",
    "\n",
    "dummy_pipeline = Pipeline([\n",
    "        ('encoder', OrdinalEncoder()),\n",
    "        ('dummies', OneHotEncoder()),\n",
    "    ])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "prep_pipeline = ColumnTransformer([\n",
    "        (\"cat\", dummy_pipeline, str_cat_vars),\n",
    "        (\"num\", StandardScaler(), num_vars),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = prep_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.84745082,\n",
       "         0.19474007, -0.34890404],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.84745082,\n",
       "         0.19474007, -0.34890404],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -0.9393463 ,\n",
       "         0.19474007, -0.34890404],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.33357351,\n",
       "         0.19474007, -0.34890404],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.9393463 ,\n",
       "         0.19474007, -0.34890404],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.9393463 ,\n",
       "         0.19474007, -0.34890404]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_prepared = prep_pipeline.transform(X_val)  # we do not *fit* the test data!\n",
    "X_test_prepared = prep_pipeline.transform(X_test)  # we do not *fit* the test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to build 2 binary classification models using any 2 of the following methods:\n",
    "1. Logistic Regression,\n",
    "2. Random Forest,\n",
    "3. GBM,\n",
    "4. Xgboost,\n",
    "5. Neural Network.\n",
    "\n",
    "Let's train the first four and see their performance and keep Nerual Nets as a cherry on a cake! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** I train the basic model in this section. I will tune hyperparameters later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I change the maximum number of iterations taken for the solvers to converge (default is 100 which is too small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we do on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996762784005755"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we do on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907742109522525"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I leave model evaluation assessment on the test set for later analysis after I fine-tune the model with hyperparameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953240213416462"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8972214728891287"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9048018703914633"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088211491772322"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING.** XGBClassifier gives errors when printing the output (after the `fit` method?..). It seems to be an issue with Scikit-Learn version 0.23.1 and higher, see discussion here: https://github.com/dmlc/xgboost/issues/5668\n",
    "\n",
    "I updated scikit-learn to version 0.23.2 and it still appears as an error..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_mimebundle_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"text/plain\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"display\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'diagram'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text/html\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    277\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[1;32m--> 393\u001b[1;33m                                                 self._depth, level)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         return _safe_repr(object, context, maxlevels, level,\n\u001b[1;32m--> 170\u001b[1;33m                           changed_only=self._changed_only)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001b[0m\u001b[0;32m     99\u001b[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001b[0;32m    100\u001b[0m             \u001b[0mfiltered_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_score'"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    403\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                             \u001b[1;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    277\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[1;32m--> 393\u001b[1;33m                                                 self._depth, level)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         return _safe_repr(object, context, maxlevels, level,\n\u001b[1;32m--> 170\u001b[1;33m                           changed_only=self._changed_only)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001b[0m\u001b[0;32m     99\u001b[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001b[0;32m    100\u001b[0m             \u001b[0mfiltered_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_score'"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "xgb_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9294406810143276"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906123550040464"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 Preliminary Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that Random Forest and Gradient Boosting classifiers overfit on the training set, Logistic Regression does not overfit on the training set, and XGBoost classifier overfits slightly.\n",
    "All four classifiers show similar performance on the validation set: ~90% accuracy.\n",
    "Therefore, we have to do some regularization and hyperparameter tuning, as well as some feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Improving the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to come up with some new features that may better explain the outcome variable.\n",
    "There are few general ways to generate new features.\n",
    "1. Adding polynomial features.\n",
    "2. Categorizing continuous variables;\n",
    "3. Combining the existing features to produce new, meaningful ones;\n",
    "\n",
    "The first option is used when we do not want to give a thought about what features we want to use. This option might be useful when we underfit the data (not our case). Another use of this way is to produce interactions between features.\n",
    "\n",
    "The second option is used when we believe that it is not the value that is important but the groups that are defined by certain levels.\n",
    "For example, suppose we new income levels of the respondents.\n",
    "We could use categorical income variable with 3 categories: 'low', 'medium', and 'high', because we might expect similar behavior of respondents in the same income group but different across those groups.\n",
    "\n",
    "The third option requires the knowledge of the problem at hand.\n",
    "Were I a banking specialist, I could design new features like \"the ratio of the number of times the client was contacted during last campaign to the number of times the client was contacted during current campaign\".\n",
    "\n",
    "For demonstration purposes, I do all three steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'campaign', 'cons.conf.idx', 'cons.price.idx',\n",
       "       'emp.var.rate', 'euribor3m', 'nr.employed', 'pdays', 'previous'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually combine existing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add features created manually to the pipeline, we need to define a class that returns self on fit (does nothing) and returns a numpy array with additional feature.\n",
    "\n",
    "**Note:** This class operates on numerical features only, so we will construct an additional pipeline to deal with all numeric features at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\"\"\"\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\"\"\"\n",
    "\n",
    "current_c_ix, past_c_ix = 1, 8\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_num_contacts_ratio = True):  # no *args or **kargs\n",
    "        self.add_num_contacts_ratio = add_num_contacts_ratio\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        if self.add_num_contacts_ratio:\n",
    "            num_contacts_ratio = X[:, past_c_ix] / X[:, current_c_ix]\n",
    "            return np.c_[X, num_contacts_ratio]\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adder = CombinedAttributesAdder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>age</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>...</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>98</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>76</td>\n",
       "      <td>142</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "age    17  18  19  20  21  22   23   24   25   26  ...  83  84  85  86  87  \\\n",
       "row_0                                              ...                       \n",
       "0       2  16  18  34  61  76  142  313  401  472  ...   5   4   5   1   0   \n",
       "1       2   7  16  20  22  30   38   73   75  102  ...   5   3   5   4   1   \n",
       "\n",
       "age    88  89  91  92  98  \n",
       "row_0                      \n",
       "0       8   0   2   0   0  \n",
       "1       9   2   0   3   1  \n",
       "\n",
       "[2 rows x 76 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, X_train['age'], margins = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the clients' age varies a lot. Let's build a dummy variable that represents that the person has not yet reached the retirement age (66.5 years in Portugal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold=66.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to keep in mind that if we replace `age` variable with a binary variable defined above, we need to exclude `age` from numeric variables `num_vars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vars = ['age',]\n",
    "\n",
    "new_num_vars = np.setdiff1d(num_vars, binary_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** we could also use an alternative way - use `KBinsDiscretizer` to bin continuous data into intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add quadratic features (polynomial with $n=2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Build a New Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numeric features\n",
    "col_transformer = ColumnTransformer([\n",
    "        (\"categorizer\", dummy_pipeline, str_cat_vars),\n",
    "        (\"binarizer\", Binarizer(threshold=66.5), binary_vars),\n",
    "        (\"scaler\", StandardScaler(), new_num_vars),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('col_transformer', col_transformer),\n",
    "    (\"poly_features\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_complete = full_pipeline.fit_transform(X_train)\n",
    "X_val_complete = full_pipeline.transform(X_val)\n",
    "X_test_complete = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33362, 20), (33362, 2015))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression trained in 103.41946268081665s\n",
      "Train accuracy: 0.9082489059408908, val accuracy: 0.9018073914216348\n"
     ]
    }
   ],
   "source": [
    "t_lr = time.time()\n",
    "log_reg.fit(X_train_complete, y_train)\n",
    "print(f\"Logistic regression trained in {time.time() - t_lr}s\")\n",
    "print(f\"Train accuracy: {log_reg.score(X_train_complete, y_train)}, val accuracy: {log_reg.score(X_val_complete, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier trained in 40.053128242492676s\n",
      "Train accuracy: 0.9843534560278161, val accuracy: 0.8893984353925006\n"
     ]
    }
   ],
   "source": [
    "t_rf = time.time()\n",
    "forest_clf.fit(X_train_complete, y_train)\n",
    "print(f\"Random forest classifier trained in {time.time() - t_rf}s\")\n",
    "print(f\"Train accuracy: {forest_clf.score(X_train_complete, y_train)}, val accuracy: {forest_clf.score(X_val_complete, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting classifier trained in 353.8548309803009s\n",
      "Train accuracy: 0.9094478748276482, val accuracy: 0.9066630698678176\n"
     ]
    }
   ],
   "source": [
    "t_gb = time.time()\n",
    "\n",
    "gb_clf.fit(X_train_complete, y_train)\n",
    "print(f\"Gradient boosting classifier trained in {time.time() - t_gb}s\")\n",
    "print(f\"Train accuracy: {gb_clf.score(X_train_complete, y_train)}, val accuracy: {gb_clf.score(X_val_complete, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost classifier trained in 187.3780586719513s\n",
      "Train accuracy: 0.9302499850128889, val accuracy: 0.9009981116806043\n"
     ]
    }
   ],
   "source": [
    "t_xgb = time.time()\n",
    "xgb_clf.fit(X_train_complete, y_train)\n",
    "print(f\"XGBoost classifier trained in {time.time() - t_xgb}s\")\n",
    "print(f\"Train accuracy: {xgb_clf.score(X_train_complete, y_train)}, val accuracy: {xgb_clf.score(X_val_complete, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes quite some time to train a GB Classifier on the dataset with 30k instances and 2k features (over 5 minutes on my laptop with i5-7200 CPU 2.5GHz)...\n",
    "\n",
    "Also note that the performance has not improved, most likely because we replaced age variable with a dummy variable that is unlikely to produce meaningful predictions (I did that just to play around with the API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Random Forest and XGBoost Classifiers perform best (although RF classifier overfits the training set).\n",
    "I will tune these two models in the subsequent analysis.\n",
    "\n",
    "Furthermore, I revert binarizing `age` variable but would like to add polynomial features of degree 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier trained in 40.32072067260742s on polyfeatures (d=2)\n",
      "Train accuracy: 0.9953240213416462, val accuracy: 0.8985702724575129\n",
      "XGBoost classifier trained in 182.69800925254822s on polyfeatures (d=2)\n",
      "Train accuracy: 0.9351058090042563, val accuracy: 0.9004585918532506\n"
     ]
    }
   ],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('basic_prep', prep_pipeline),\n",
    "    (\"poly_features\", PolynomialFeatures(degree=2, include_bias=True)),\n",
    "])\n",
    "\n",
    "X_train_final = final_pipeline.fit_transform(X_train)\n",
    "X_val_final = final_pipeline.transform(X_val)\n",
    "X_test_final = final_pipeline.transform(X_test)\n",
    "\n",
    "t_rf = time.time()\n",
    "forest_clf.fit(X_train_final, y_train)\n",
    "print(f\"Random forest classifier trained in {time.time() - t_rf}s on polyfeatures (d=2)\")\n",
    "print(f\"Train accuracy: {forest_clf.score(X_train_final, y_train)}, val accuracy: {forest_clf.score(X_val_final, y_val)}\")\n",
    "\n",
    "t_xgb = time.time()\n",
    "xgb_clf.fit(X_train_final, y_train)\n",
    "print(f\"XGBoost classifier trained in {time.time() - t_xgb}s on polyfeatures (d=2)\")\n",
    "print(f\"Train accuracy: {xgb_clf.score(X_train_final, y_train)}, val accuracy: {xgb_clf.score(X_val_final, y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, well, well... It seems that adding polynomial features did not help at all but slowed down my algorithm.\n",
    "The best approach is the simplest approach, right?.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** *Please, keep in mind that the cross-validation methods presented below might take much longer time to run on your local machine!.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two classes in `Scikit-Learn` that help us tune hyperparameter:\n",
    "1. `GridSearchCV`, and\n",
    "2. `RandomizedSearchCV`.\n",
    "\n",
    "Let's try both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** I will *not* try grid search cross-validation for the degrees of polynomial features or other pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Cross-Validation for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV for RF classifier trained in 345.16774129867554s on 4 cores\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = [\n",
    "    {'n_estimators': [10, 50, 100, 150, 200], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2],},\n",
    "]\n",
    "\n",
    "# Note that we ask GridSearchCV to randomly split the data into train and val sets 5 times\n",
    "# GridSearchCV automatically uses StratifiedKFold splitter\n",
    "# if the estimator is a classifier and y is either binary or multiclass\n",
    "rf_grid_search = GridSearchCV(rf_clf, rf_param_grid, cv=5, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "# because of that splitter we can use the whole train+val set to feed to GridSearchCV\n",
    "X_trainval_prepared = prep_pipeline.transform(X_trainval)  # let's use the scaler we fit on the *train* set\n",
    "\n",
    "t_rf_GridSearchCV = time.time()\n",
    "rf_grid_search.fit(X_trainval_prepared, y_trainval)\n",
    "print(f\"GridSearchCV for RF classifier trained in {time.time() - t_rf_GridSearchCV}s on 4 cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261377431276808"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_estimator_.score(X_trainval_prepared, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8997329448895363"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_estimator_.score(X_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. But also not an outstanding result. We clearly avoid overfitting (compared to the first prototypes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search Cross-Validation for XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not create a learning rate schedule. Instead, I will use randomized search to tune the LR and the penalty parameter for L2 regularization (`reg_lambda = 1` by default in XGBClassifier with the default `booster = gbtree`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 20.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV for XGBoost classifier trained in 1249.4742312431335s on 4 cores\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb_param_dist = {\n",
    "    'learning_rate': reciprocal(0.01, 10),\n",
    "    'reg_lambda': expon(scale=1.),\n",
    "}\n",
    "\n",
    "xgb_randomized_search = RandomizedSearchCV(xgb_clf, param_distributions=xgb_param_dist,\n",
    "                                           n_iter=50, cv=5, verbose=2, random_state=42,\n",
    "                                           n_jobs=-1)\n",
    "\n",
    "t_xgb_RandomizedSearchCV = time.time()\n",
    "xgb_randomized_search.fit(X_trainval_prepared, y_trainval)\n",
    "print(f\"RandomizedSearchCV for XGBoost classifier trained in {time.time() - t_xgb_RandomizedSearchCV}s on 4 cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.010388823104027934, 'reg_lambda': 1.689896777486126}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_mimebundle_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"text/plain\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"display\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'diagram'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text/html\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    277\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[1;32m--> 393\u001b[1;33m                                                 self._depth, level)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         return _safe_repr(object, context, maxlevels, level,\n\u001b[1;32m--> 170\u001b[1;33m                           changed_only=self._changed_only)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001b[0m\u001b[0;32m     99\u001b[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001b[0;32m    100\u001b[0m             \u001b[0mfiltered_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_score'"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    403\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                             \u001b[1;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    277\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[1;32m--> 393\u001b[1;33m                                                 self._depth, level)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         return _safe_repr(object, context, maxlevels, level,\n\u001b[1;32m--> 170\u001b[1;33m                           changed_only=self._changed_only)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001b[0m\u001b[0;32m     99\u001b[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001b[0;32m    100\u001b[0m             \u001b[0mfiltered_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_score'"
     ]
    }
   ],
   "source": [
    "xgb_randomized_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-ha! Same error as above, when printing out the estimator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9064177614718498"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_randomized_search.best_estimator_.score(X_trainval_prepared, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999757222626851"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_randomized_search.best_estimator_.score(X_test_prepared, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... We clearly avoided overfitting. BUT we did not get much imporvement either (compared to the first prototypes with the default parameters).\n",
    "\n",
    "Let's build a soft voting classifier on top of these two and, maybe, try an SVM Classifier (should work fine as we have less than 100k instances and 20 features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.010388823104027934, 'reg_lambda': 1.689896777486126}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_randomized_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rxgb_clf = XGBClassifier(**xgb_randomized_search.best_params_, random_state=42)\n",
    "rrf_clf = RandomForestClassifier(**rf_grid_search.best_params_, random_state=42)\n",
    "# I was wrong, it takes some enormous time to train SVM classifier with this number of instances...\n",
    "# svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "# I will not train or use SVC in subsequent analysis or in the voting classifier, as I planned initially.\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', rxgb_clf), ('rf', rrf_clf)],\n",
    "    voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier 0.8982762806506434\n",
      "RandomForestClassifier 0.8926924010682205\n",
      "VotingClassifier 0.8997329448895363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (rxgb_clf, rf_clf, voting_clf):\n",
    "    clf.fit(X_train_prepared, y_train)\n",
    "    y_pred = clf.predict(X_test_prepared)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft Voting Classifier did not provide much better results (althouth, the accuracy on the test set is 0.15% higher than for XGBClassifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 A Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=.01),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.3064 - accuracy: 0.8942 - val_loss: 0.2817 - val_accuracy: 0.9029\n",
      "Epoch 2/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2816 - accuracy: 0.8992 - val_loss: 0.2790 - val_accuracy: 0.9013\n",
      "Epoch 3/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2788 - accuracy: 0.8998 - val_loss: 0.2770 - val_accuracy: 0.9034\n",
      "Epoch 4/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2773 - accuracy: 0.9005 - val_loss: 0.2762 - val_accuracy: 0.9040\n",
      "Epoch 5/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2761 - accuracy: 0.9004 - val_loss: 0.2761 - val_accuracy: 0.9032\n",
      "Epoch 6/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2753 - accuracy: 0.9010 - val_loss: 0.2750 - val_accuracy: 0.9034\n",
      "Epoch 7/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2745 - accuracy: 0.9012 - val_loss: 0.2753 - val_accuracy: 0.9050\n",
      "Epoch 8/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2739 - accuracy: 0.9015 - val_loss: 0.2746 - val_accuracy: 0.9032\n",
      "Epoch 9/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2735 - accuracy: 0.9008 - val_loss: 0.2761 - val_accuracy: 0.9021\n",
      "Epoch 10/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2731 - accuracy: 0.9014 - val_loss: 0.2743 - val_accuracy: 0.9040\n",
      "Epoch 11/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2725 - accuracy: 0.9005 - val_loss: 0.2737 - val_accuracy: 0.9053\n",
      "Epoch 12/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2721 - accuracy: 0.9013 - val_loss: 0.2737 - val_accuracy: 0.9042\n",
      "Epoch 13/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2716 - accuracy: 0.9017 - val_loss: 0.2733 - val_accuracy: 0.9053\n",
      "Epoch 14/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2713 - accuracy: 0.9016 - val_loss: 0.2735 - val_accuracy: 0.9053\n",
      "Epoch 15/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2709 - accuracy: 0.9011 - val_loss: 0.2735 - val_accuracy: 0.9050\n",
      "Epoch 16/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2706 - accuracy: 0.9017 - val_loss: 0.2727 - val_accuracy: 0.9067\n",
      "Epoch 17/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2702 - accuracy: 0.9020 - val_loss: 0.2725 - val_accuracy: 0.9067\n",
      "Epoch 18/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2699 - accuracy: 0.9018 - val_loss: 0.2743 - val_accuracy: 0.9053\n",
      "Epoch 19/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2695 - accuracy: 0.9024 - val_loss: 0.2727 - val_accuracy: 0.9048\n",
      "Epoch 20/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2692 - accuracy: 0.9024 - val_loss: 0.2727 - val_accuracy: 0.9067\n",
      "Epoch 21/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2686 - accuracy: 0.9026 - val_loss: 0.2740 - val_accuracy: 0.9034\n",
      "Epoch 22/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2685 - accuracy: 0.9026 - val_loss: 0.2729 - val_accuracy: 0.9048\n",
      "Epoch 23/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2682 - accuracy: 0.9028 - val_loss: 0.2726 - val_accuracy: 0.9050\n",
      "Epoch 24/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2678 - accuracy: 0.9028 - val_loss: 0.2727 - val_accuracy: 0.9053\n",
      "Epoch 25/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2675 - accuracy: 0.9032 - val_loss: 0.2729 - val_accuracy: 0.9042\n",
      "Epoch 26/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2671 - accuracy: 0.9033 - val_loss: 0.2731 - val_accuracy: 0.9034\n",
      "Epoch 27/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2667 - accuracy: 0.9036 - val_loss: 0.2737 - val_accuracy: 0.9018\n",
      "Epoch 28/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2665 - accuracy: 0.9033 - val_loss: 0.2730 - val_accuracy: 0.9048\n",
      "Epoch 29/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2661 - accuracy: 0.9029 - val_loss: 0.2725 - val_accuracy: 0.9056\n",
      "Epoch 30/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2656 - accuracy: 0.9035 - val_loss: 0.2727 - val_accuracy: 0.9045\n",
      "Epoch 31/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2655 - accuracy: 0.9034 - val_loss: 0.2726 - val_accuracy: 0.9048\n",
      "Epoch 32/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2650 - accuracy: 0.9034 - val_loss: 0.2721 - val_accuracy: 0.9069\n",
      "Epoch 33/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2646 - accuracy: 0.9044 - val_loss: 0.2715 - val_accuracy: 0.9064\n",
      "Epoch 34/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2642 - accuracy: 0.9038 - val_loss: 0.2730 - val_accuracy: 0.9045\n",
      "Epoch 35/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2640 - accuracy: 0.9041 - val_loss: 0.2720 - val_accuracy: 0.9064\n",
      "Epoch 36/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2635 - accuracy: 0.9039 - val_loss: 0.2738 - val_accuracy: 0.9013\n",
      "Epoch 37/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2632 - accuracy: 0.9045 - val_loss: 0.2721 - val_accuracy: 0.9050\n",
      "Epoch 38/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2629 - accuracy: 0.9035 - val_loss: 0.2722 - val_accuracy: 0.9042\n",
      "Epoch 39/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2625 - accuracy: 0.9038 - val_loss: 0.2717 - val_accuracy: 0.9053\n",
      "Epoch 40/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2622 - accuracy: 0.9043 - val_loss: 0.2728 - val_accuracy: 0.9048\n",
      "Epoch 41/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2619 - accuracy: 0.9039 - val_loss: 0.2761 - val_accuracy: 0.9005\n",
      "Epoch 42/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2614 - accuracy: 0.9052 - val_loss: 0.2720 - val_accuracy: 0.9040\n",
      "Epoch 43/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2611 - accuracy: 0.9047 - val_loss: 0.2722 - val_accuracy: 0.9045\n",
      "Epoch 44/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2605 - accuracy: 0.9057 - val_loss: 0.2715 - val_accuracy: 0.9053\n",
      "Epoch 45/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2601 - accuracy: 0.9049 - val_loss: 0.2731 - val_accuracy: 0.9023\n",
      "Epoch 46/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2599 - accuracy: 0.9058 - val_loss: 0.2728 - val_accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2595 - accuracy: 0.9055 - val_loss: 0.2722 - val_accuracy: 0.9040\n",
      "Epoch 48/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2591 - accuracy: 0.9059 - val_loss: 0.2732 - val_accuracy: 0.9045\n",
      "Epoch 49/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2588 - accuracy: 0.9058 - val_loss: 0.2733 - val_accuracy: 0.9037\n",
      "Epoch 50/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2583 - accuracy: 0.9054 - val_loss: 0.2733 - val_accuracy: 0.9045\n",
      "Epoch 51/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2580 - accuracy: 0.9058 - val_loss: 0.2733 - val_accuracy: 0.9040\n",
      "Epoch 52/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2577 - accuracy: 0.9066 - val_loss: 0.2733 - val_accuracy: 0.9050\n",
      "Epoch 53/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2573 - accuracy: 0.9061 - val_loss: 0.2735 - val_accuracy: 0.9042\n",
      "Epoch 54/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2566 - accuracy: 0.9066 - val_loss: 0.2732 - val_accuracy: 0.9059\n",
      "Epoch 55/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2565 - accuracy: 0.9064 - val_loss: 0.2728 - val_accuracy: 0.9040\n",
      "Epoch 56/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2560 - accuracy: 0.9065 - val_loss: 0.2740 - val_accuracy: 0.9045\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2558 - accuracy: 0.9060 - val_loss: 0.2734 - val_accuracy: 0.9037\n",
      "Epoch 58/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2551 - accuracy: 0.9075 - val_loss: 0.2740 - val_accuracy: 0.9048\n",
      "Epoch 59/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2547 - accuracy: 0.9070 - val_loss: 0.2750 - val_accuracy: 0.9029\n",
      "Epoch 60/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2544 - accuracy: 0.9077 - val_loss: 0.2740 - val_accuracy: 0.9050\n",
      "Epoch 61/100\n",
      "1043/1043 [==============================] - 2s 2ms/step - loss: 0.2540 - accuracy: 0.9076 - val_loss: 0.2745 - val_accuracy: 0.9045\n",
      "Epoch 62/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2537 - accuracy: 0.9079 - val_loss: 0.2734 - val_accuracy: 0.9042\n",
      "Epoch 63/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2531 - accuracy: 0.9079 - val_loss: 0.2745 - val_accuracy: 0.9026\n",
      "Epoch 64/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2529 - accuracy: 0.9082 - val_loss: 0.2742 - val_accuracy: 0.9040\n",
      "Epoch 65/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2523 - accuracy: 0.9084 - val_loss: 0.2748 - val_accuracy: 0.9026\n",
      "Epoch 66/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2523 - accuracy: 0.9085 - val_loss: 0.2775 - val_accuracy: 0.9021\n",
      "Epoch 67/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2518 - accuracy: 0.9085 - val_loss: 0.2763 - val_accuracy: 0.9013\n",
      "Epoch 68/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2515 - accuracy: 0.9083 - val_loss: 0.2756 - val_accuracy: 0.9037\n",
      "Epoch 69/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2509 - accuracy: 0.9088 - val_loss: 0.2781 - val_accuracy: 0.9013\n",
      "Epoch 70/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2502 - accuracy: 0.9094 - val_loss: 0.2761 - val_accuracy: 0.9037\n",
      "Epoch 71/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2502 - accuracy: 0.9085 - val_loss: 0.2775 - val_accuracy: 0.8986\n",
      "Epoch 72/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2495 - accuracy: 0.9086 - val_loss: 0.2764 - val_accuracy: 0.9005\n",
      "Epoch 73/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2489 - accuracy: 0.9095 - val_loss: 0.2811 - val_accuracy: 0.9005\n",
      "Epoch 74/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2487 - accuracy: 0.9094 - val_loss: 0.2778 - val_accuracy: 0.9042\n",
      "Epoch 75/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2482 - accuracy: 0.9096 - val_loss: 0.2769 - val_accuracy: 0.9023\n",
      "Epoch 76/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2480 - accuracy: 0.9096 - val_loss: 0.2773 - val_accuracy: 0.9013\n",
      "Epoch 77/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2475 - accuracy: 0.9096 - val_loss: 0.2775 - val_accuracy: 0.9026\n",
      "Epoch 78/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2469 - accuracy: 0.9099 - val_loss: 0.2785 - val_accuracy: 0.9032\n",
      "Epoch 79/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2464 - accuracy: 0.9098 - val_loss: 0.2860 - val_accuracy: 0.8953\n",
      "Epoch 80/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2458 - accuracy: 0.9100 - val_loss: 0.2829 - val_accuracy: 0.9010\n",
      "Epoch 81/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2452 - accuracy: 0.9111 - val_loss: 0.2821 - val_accuracy: 0.8988\n",
      "Epoch 82/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2452 - accuracy: 0.9104 - val_loss: 0.2791 - val_accuracy: 0.9015\n",
      "Epoch 83/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2448 - accuracy: 0.9104 - val_loss: 0.2824 - val_accuracy: 0.8994\n",
      "Epoch 84/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2444 - accuracy: 0.9107 - val_loss: 0.2815 - val_accuracy: 0.8994\n",
      "Epoch 85/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2438 - accuracy: 0.9106 - val_loss: 0.2802 - val_accuracy: 0.9032\n",
      "Epoch 86/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2431 - accuracy: 0.9109 - val_loss: 0.2815 - val_accuracy: 0.9029\n",
      "Epoch 87/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2430 - accuracy: 0.9113 - val_loss: 0.2824 - val_accuracy: 0.9053\n",
      "Epoch 88/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2426 - accuracy: 0.9118 - val_loss: 0.2868 - val_accuracy: 0.9013\n",
      "Epoch 89/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2422 - accuracy: 0.9108 - val_loss: 0.2791 - val_accuracy: 0.9021\n",
      "Epoch 90/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2409 - accuracy: 0.9117 - val_loss: 0.2866 - val_accuracy: 0.9034\n",
      "Epoch 91/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2411 - accuracy: 0.9120 - val_loss: 0.2819 - val_accuracy: 0.9015\n",
      "Epoch 92/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2407 - accuracy: 0.9121 - val_loss: 0.2821 - val_accuracy: 0.9037\n",
      "Epoch 93/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2399 - accuracy: 0.9124 - val_loss: 0.2824 - val_accuracy: 0.9005\n",
      "Epoch 94/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2397 - accuracy: 0.9120 - val_loss: 0.2841 - val_accuracy: 0.9023\n",
      "Epoch 95/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2389 - accuracy: 0.9127 - val_loss: 0.2822 - val_accuracy: 0.9034\n",
      "Epoch 96/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2386 - accuracy: 0.9139 - val_loss: 0.2856 - val_accuracy: 0.9013\n",
      "Epoch 97/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2378 - accuracy: 0.9129 - val_loss: 0.2830 - val_accuracy: 0.8996\n",
      "Epoch 98/100\n",
      "1043/1043 [==============================] - 1s 1ms/step - loss: 0.2372 - accuracy: 0.9124 - val_loss: 0.2827 - val_accuracy: 0.9026\n",
      "Epoch 99/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2371 - accuracy: 0.9129 - val_loss: 0.2838 - val_accuracy: 0.9050\n",
      "Epoch 100/100\n",
      "1043/1043 [==============================] - 2s 1ms/step - loss: 0.2363 - accuracy: 0.9127 - val_loss: 0.2833 - val_accuracy: 0.9029\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_prepared,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_prepared, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1217562 ],\n",
       "       [0.34475255],\n",
       "       [0.94861007],\n",
       "       ...,\n",
       "       [0.12860693],\n",
       "       [0.00728785],\n",
       "       [0.01481945]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_nn = model.predict(X_test_prepared)\n",
    "y_pred_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953629521728574"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, (y_pred_nn>=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that such a simple NN does not provide a better forecast than a Soft Voting Classifier.\n",
    "Perhaps, using polynomial features and/or a deeper network would help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Deeper NN with Optimal Stopping, Dropout Regularization, and LR Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_model_1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use keras scheduler callback\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "# use early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "# I will *not* use tensorboard\n",
    "\n",
    "# NAdam is RMSprop with Nesterov momentum\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "deeper_model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2911 - accuracy: 0.8967 - val_loss: 0.2754 - val_accuracy: 0.9032 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2814 - accuracy: 0.8991 - val_loss: 0.2789 - val_accuracy: 0.9072 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2791 - accuracy: 0.9014 - val_loss: 0.2783 - val_accuracy: 0.9007 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2769 - accuracy: 0.9008 - val_loss: 0.2746 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2748 - accuracy: 0.9008 - val_loss: 0.2782 - val_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2717 - accuracy: 0.9016 - val_loss: 0.2759 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2694 - accuracy: 0.9032 - val_loss: 0.2741 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2674 - accuracy: 0.9033 - val_loss: 0.2769 - val_accuracy: 0.9064 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2649 - accuracy: 0.9038 - val_loss: 0.2788 - val_accuracy: 0.9032 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2617 - accuracy: 0.9048 - val_loss: 0.2766 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2568 - accuracy: 0.9062 - val_loss: 0.2804 - val_accuracy: 0.9059 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2554 - accuracy: 0.9061 - val_loss: 0.2813 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2417 - accuracy: 0.9110 - val_loss: 0.2852 - val_accuracy: 0.9042 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2340 - accuracy: 0.9121 - val_loss: 0.2975 - val_accuracy: 0.9034 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2298 - accuracy: 0.9135 - val_loss: 0.3073 - val_accuracy: 0.9007 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2239 - accuracy: 0.9159 - val_loss: 0.3052 - val_accuracy: 0.8994 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "1043/1043 [==============================] - 4s 4ms/step - loss: 0.2192 - accuracy: 0.9182 - val_loss: 0.3158 - val_accuracy: 0.9002 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "dnn_history = deeper_model_1.fit(\n",
    "    X_train_prepared,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_prepared, y_val),\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1915324 ],\n",
       "       [0.4149238 ],\n",
       "       [0.98910236],\n",
       "       ...,\n",
       "       [0.0935342 ],\n",
       "       [0.00656125],\n",
       "       [0.00723361]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dnn = deeper_model_1.predict(X_test_prepared)\n",
    "y_pred_dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896091284292304"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, (y_pred_dnn>=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With basic set of features (i.e. without an appropriate feature engineering) the NNets do not provide a better forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 DNN on Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_model_1 = keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use keras scheduler callback\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "# use early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "# I will *not* use tensorboard\n",
    "\n",
    "# NAdam is RMSprop with Nesterov momentum\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "deeper_model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1043/1043 [==============================] - 21s 21ms/step - loss: 0.2980 - accuracy: 0.8948 - val_loss: 0.2776 - val_accuracy: 0.9032 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.2837 - accuracy: 0.8989 - val_loss: 0.2897 - val_accuracy: 0.9069 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.2776 - accuracy: 0.9005 - val_loss: 0.2780 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.2737 - accuracy: 0.9009 - val_loss: 0.2785 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.2698 - accuracy: 0.9023 - val_loss: 0.2846 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1043/1043 [==============================] - 23s 22ms/step - loss: 0.2654 - accuracy: 0.9036 - val_loss: 0.2830 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.2513 - accuracy: 0.9072 - val_loss: 0.2802 - val_accuracy: 0.9053 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "1043/1043 [==============================] - 25s 24ms/step - loss: 0.2410 - accuracy: 0.9103 - val_loss: 0.2916 - val_accuracy: 0.9007 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "1043/1043 [==============================] - 23s 22ms/step - loss: 0.2295 - accuracy: 0.9134 - val_loss: 0.3054 - val_accuracy: 0.8996 - lr: 5.0000e-04\n",
      "Epoch 10/100\n",
      "1043/1043 [==============================] - 23s 22ms/step - loss: 0.2184 - accuracy: 0.9158 - val_loss: 0.3194 - val_accuracy: 0.8961 - lr: 5.0000e-04\n",
      "Epoch 11/100\n",
      "1043/1043 [==============================] - 22s 21ms/step - loss: 0.2066 - accuracy: 0.9200 - val_loss: 0.3421 - val_accuracy: 0.8956 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "dnn_history = deeper_model_1.fit(\n",
    "    X_train_final,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val_final, y_val),\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8924496236950716"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dnn = deeper_model_1.predict(X_test_final)\n",
    "accuracy_score(y_test, (y_pred_dnn>=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well... I think that feature engineering for this task requires much more attention!.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed since the start of the script: 3046.453991651535s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time elapsed since the start of the script: {time.time() - t0}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
