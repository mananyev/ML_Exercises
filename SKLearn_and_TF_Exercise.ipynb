{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==0.9.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: appdirs==1.4.4 in c:\\users\\anany\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: astor==0.8.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.9.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 5)) (4.9.1)\n",
      "Requirement already satisfied: blinker==1.4 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 6)) (1.4)\n",
      "Requirement already satisfied: brotlipy==0.7.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: bs4==0.0.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 8)) (0.0.1)\n",
      "Requirement already satisfied: cachetools@ file:///tmp/build/80754af9/cachetools_1596822027882/work from file:///tmp/build/80754af9/cachetools_1596822027882/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 9)) (4.1.1)\n",
      "Requirement already satisfied: certifi==2020.6.20 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 10)) (2020.6.20)\n",
      "Requirement already satisfied: cffi==1.14.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 11)) (1.14.0)\n",
      "Requirement already satisfied: chardet==3.0.4 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 12)) (3.0.4)\n",
      "Requirement already satisfied: click==7.1.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 13)) (7.1.2)\n",
      "Requirement already satisfied: colorama==0.4.3 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 14)) (0.4.3)\n",
      "Requirement already satisfied: cryptography==2.9.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 15)) (2.9.2)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 16)) (0.10.0)\n",
      "Requirement already satisfied: decorator==4.4.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 17)) (4.4.2)\n",
      "Requirement already satisfied: distlib==0.3.0 in c:\\users\\anany\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 18)) (0.3.0)\n",
      "Requirement already satisfied: filelock==3.0.12 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 19)) (3.0.12)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 20)) (0.2.2)\n",
      "Requirement already satisfied: google-auth@ file:///tmp/build/80754af9/google-auth_1596863485713/work from file:///tmp/build/80754af9/google-auth_1596863485713/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 21)) (1.20.1)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 22)) (0.4.1)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 23)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.27.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 24)) (1.27.2)\n",
      "Requirement already satisfied: h5py==2.10.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 25)) (2.10.0)\n",
      "Requirement already satisfied: idna@ file:///tmp/build/80754af9/idna_1593446292537/work from file:///tmp/build/80754af9/idna_1593446292537/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 26)) (2.10)\n",
      "Requirement already satisfied: importlib-metadata==1.7.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 27)) (1.7.0)\n",
      "Requirement already satisfied: ipython@ file:///C:/ci/ipython_1596868620883/work from file:///C:/ci/ipython_1596868620883/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 28)) (7.17.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 29)) (0.2.0)\n",
      "Requirement already satisfied: jedi@ file:///C:/ci/jedi_1596472767194/work from file:///C:/ci/jedi_1596472767194/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 30)) (0.17.2)\n",
      "Requirement already satisfied: joblib@ file:///tmp/build/80754af9/joblib_1594236160679/work from file:///tmp/build/80754af9/joblib_1594236160679/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 31)) (0.16.0)\n",
      "Requirement already satisfied: Keras-Applications@ file:///tmp/build/80754af9/keras-applications_1594366238411/work from file:///tmp/build/80754af9/keras-applications_1594366238411/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 32)) (1.0.8)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 33)) (1.1.0)\n",
      "Requirement already satisfied: kiwisolver==1.2.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 34)) (1.2.0)\n",
      "Requirement already satisfied: Markdown==3.1.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 35)) (3.1.1)\n",
      "Requirement already satisfied: matplotlib@ file:///C:/ci/matplotlib-base_1592846084747/work from file:///C:/ci/matplotlib-base_1592846084747/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 36)) (3.2.2)\n",
      "Requirement already satisfied: mkl-fft==1.0.14 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 37)) (1.0.14)\n",
      "Requirement already satisfied: mkl-random==1.0.4 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 38)) (1.0.4)\n",
      "Requirement already satisfied: mkl-service==2.3.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 39)) (2.3.0)\n",
      "Requirement already satisfied: numpy==1.17.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 40)) (1.17.0)\n",
      "Requirement already satisfied: oauthlib==3.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 41)) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum==3.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 42)) (3.1.0)\n",
      "Requirement already satisfied: pandas@ file:///C:/ci/pandas_1596824386248/work from file:///C:/ci/pandas_1596824386248/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 43)) (1.1.0)\n",
      "Requirement already satisfied: parso==0.7.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 44)) (0.7.0)\n",
      "Requirement already satisfied: pickleshare@ file:///C:/ci/pickleshare_1594374056827/work from file:///C:/ci/pickleshare_1594374056827/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 45)) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.5 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 46)) (3.0.5)\n",
      "Requirement already satisfied: protobuf==3.11.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 47)) (3.11.2)\n",
      "Requirement already satisfied: py4j@ file:///tmp/build/80754af9/py4j_1593437928427/work from file:///tmp/build/80754af9/py4j_1593437928427/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 48)) (0.10.9)\n",
      "Requirement already satisfied: pyarrow==0.15.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 49)) (0.15.1)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 50)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.7 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 51)) (0.2.7)\n",
      "Requirement already satisfied: pycparser@ file:///tmp/build/80754af9/pycparser_1594388511720/work from file:///tmp/build/80754af9/pycparser_1594388511720/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 52)) (2.20)\n",
      "Requirement already satisfied: Pygments==2.6.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 53)) (2.6.1)\n",
      "Requirement already satisfied: PyJWT==1.7.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 54)) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL@ file:///tmp/build/80754af9/pyopenssl_1594392929924/work from file:///tmp/build/80754af9/pyopenssl_1594392929924/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 55)) (19.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 56)) (2.4.7)\n",
      "Requirement already satisfied: pyreadline==2.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 57)) (2.1)\n",
      "Requirement already satisfied: PySocks@ file:///C:/ci/pysocks_1594394709107/work from file:///C:/ci/pysocks_1594394709107/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 58)) (1.7.1)\n",
      "Requirement already satisfied: pyspark@ file:///tmp/build/80754af9/pyspark_1593438048599/work from file:///tmp/build/80754af9/pyspark_1593438048599/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 59)) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 60)) (2.8.1)\n",
      "Requirement already satisfied: pytz==2020.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 61)) (2020.1)\n",
      "Requirement already satisfied: requests@ file:///tmp/build/80754af9/requests_1592841827918/work from file:///tmp/build/80754af9/requests_1592841827918/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 62)) (2.24.0)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 63)) (1.3.0)\n",
      "Requirement already satisfied: rsa@ file:///tmp/build/80754af9/rsa_1596998415516/work from file:///tmp/build/80754af9/rsa_1596998415516/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 64)) (4.6)\n",
      "Requirement already satisfied: scikit-learn@ file:///C:/ci/scikit-learn_1592847564598/work from file:///C:/ci/scikit-learn_1592847564598/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 65)) (0.23.2)\n",
      "Requirement already satisfied: scipy==1.5.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 66)) (1.5.2)\n",
      "Requirement already satisfied: six==1.15.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 67)) (1.15.0)\n",
      "Requirement already satisfied: soupsieve==2.0.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 68)) (2.0.1)\n",
      "Requirement already satisfied: tensorboard==2.2.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 69)) (2.2.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.6.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 70)) (1.6.0)\n",
      "Requirement already satisfied: tensorflow==2.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 71)) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator==2.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 72)) (2.1.0)\n",
      "Requirement already satisfied: termcolor==1.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 73)) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl@ file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl from file:///tmp/tmp9twdgx9k/threadpoolctl-2.1.0-py3-none-any.whl in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 74)) (2.1.0)\n",
      "Requirement already satisfied: tornado==6.0.4 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 75)) (6.0.4)\n",
      "Requirement already satisfied: traitlets==4.3.3 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 76)) (4.3.3)\n",
      "Requirement already satisfied: urllib3==1.25.10 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 77)) (1.25.10)\n",
      "Requirement already satisfied: virtualenv==20.0.20 in c:\\users\\anany\\appdata\\roaming\\python\\python37\\site-packages (from -r requirements.txt (line 78)) (20.0.20)\n",
      "Requirement already satisfied: wcwidth@ file:///tmp/build/80754af9/wcwidth_1593447189090/work from file:///tmp/build/80754af9/wcwidth_1593447189090/work in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 79)) (0.2.5)\n",
      "Requirement already satisfied: Werkzeug==0.16.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 80)) (0.16.1)\n",
      "Requirement already satisfied: win-inet-pton==1.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 81)) (1.1.0)\n",
      "Requirement already satisfied: wincertstore==0.2 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 82)) (0.2)\n",
      "Requirement already satisfied: wrapt==1.12.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 83)) (1.12.1)\n",
      "Requirement already satisfied: xgboost==1.1.1 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 84)) (1.1.1)\n",
      "Requirement already satisfied: zipp==3.1.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from -r requirements.txt (line 85)) (3.1.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from google-auth@ file:///tmp/build/80754af9/google-auth_1596863485713/work->-r requirements.txt (line 21)) (49.3.1.post20200810)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\envs\\zeta_pyspark\\lib\\site-packages (from tensorboard==2.2.1->-r requirements.txt (line 69)) (0.34.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my gereneral imports\n",
    "import os\n",
    "import wget\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "# url data reader imports\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Scikit-Learn imports\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT = \"Bank\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\", PROJECT)\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "OUT_PATH = os.path.join(PROJECT_ROOT_DIR, \"output\", PROJECT)\n",
    "os.makedirs(OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Modelling Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build 2 binary classification models using any 2 of the following methods (in R or Python):\n",
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. GBM\n",
    "4. Xgboost\n",
    "5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 579043 / 579043"
     ]
    }
   ],
   "source": [
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00222/\"\n",
    "ext = 'zip'\n",
    "\n",
    "def list_files(url, ext=''):\n",
    "    page = requests.get(url).text\n",
    "#     print(page)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "\n",
    "for fileurl in list_files(url, ext):\n",
    "#     print(fileurl)\n",
    "    filename = fileurl.split('/')[-1]\n",
    "#     print(filename)\n",
    "    wget.download(fileurl, out=os.path.join(DATA_PATH, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bank (1).zip', 'bank-additional (1).zip', 'bank-additional.zip', 'bank.zip']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Read the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the data states that there are four datasets.\n",
    "We need\n",
    "> (1) `bank-additional-full.csv` with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014].[<sup>1</sup>](#fn1)\n",
    "\n",
    "An examination of the archive `bank-additional.zip` shows that it contains a folder called `bank-additional` with the files we need.\n",
    "\n",
    "<span id=\"fn1\"><sup>1</sup>\n",
    "    S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_file = ZipFile(os.path.join(DATA_PATH, 'bank-additional.zip'))\n",
    "df = pd.read_csv(\n",
    "    zip_file.open('bank-additional/bank-additional-full.csv'),\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Variable and Data Set Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define output variable and split the data into train, dev, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     36548\n",
      "yes     4640\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['y']\n",
    "X = df.drop(columns='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41188\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the target variable is *yes* for approximately 11% of cases. If we simply split the data into 80-10-10% train/val/test sets, there is a high chance that we end up with a lot of negative examples in the dev and test sets. This, in turn, might bias our evaluation of model performance.\n",
    "\n",
    "So, there are two options, I think:\n",
    "1. to use stratified shuffling to ensure that the proportions of positive and negative examples are similar in the split data sets, or\n",
    "2. use the test set from the website:\n",
    "    > (2) `bank-additional.csv` with 10% of the examples (4119), randomly selected from (1), and 20 inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would personally prefer option 1.\n",
    "But for the sake of completeness, let's see what distribution of the target variable is in the test file from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     3668\n",
      "yes     451\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test_web = pd.read_csv(\n",
    "    zip_file.open('bank-additional/bank-additional.csv'),\n",
    "    sep=';',\n",
    "    quotechar='\"',\n",
    ")\n",
    "print(df_test_web['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear now, that the file on the website was generated using stratified shuffling.\n",
    "\n",
    "**Note:** In the PySpark exercise, the data was also split into train and test set. However, in this exercise, we are explicitly told that the test data is a subsample of the full data set.\n",
    "\n",
    "Therefore, I will use stratified shuffling to split the data into train/dev/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I put this import into the Setup section at the beginning\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     3655\n",
       "yes     464\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     32893\n",
       "yes     4176\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trainval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, stratify=y_trainval, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each of the train, dev, and test sets have roughly 11% of the positive outcomes.\n",
    "\n",
    "**Note:** such splitting method ensures that we avoid data mismatch problem, i.e. make our dev and test sets come from similar distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert our dependent variables in all the sets into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesno_dict = {'yes': 1, 'no': 0}\n",
    "y_train = y_train.map(yesno_dict).astype('int32')\n",
    "y_val = y_val.map(yesno_dict).astype('int32')\n",
    "y_test = y_test.map(yesno_dict).astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first explore the data to see what variables are continuous, what are needed to be categorized, and what are to be transformed into dummy variables (one-hot encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33362 entries, 22373 to 31364\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             33362 non-null  int64  \n",
      " 1   job             33362 non-null  object \n",
      " 2   marital         33362 non-null  object \n",
      " 3   education       33362 non-null  object \n",
      " 4   default         33362 non-null  object \n",
      " 5   housing         33362 non-null  object \n",
      " 6   loan            33362 non-null  object \n",
      " 7   contact         33362 non-null  object \n",
      " 8   month           33362 non-null  object \n",
      " 9   day_of_week     33362 non-null  object \n",
      " 10  duration        33362 non-null  int64  \n",
      " 11  campaign        33362 non-null  int64  \n",
      " 12  pdays           33362 non-null  int64  \n",
      " 13  previous        33362 non-null  int64  \n",
      " 14  poutcome        33362 non-null  object \n",
      " 15  emp.var.rate    33362 non-null  float64\n",
      " 16  cons.price.idx  33362 non-null  float64\n",
      " 17  cons.conf.idx   33362 non-null  float64\n",
      " 18  euribor3m       33362 non-null  float64\n",
      " 19  nr.employed     33362 non-null  float64\n",
      "dtypes: float64(5), int64(5), object(10)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that the following variables are categorical (or binary):\n",
    "* job,\n",
    "* marital,\n",
    "* education,\n",
    "* housing,\n",
    "* loan,\n",
    "* contact,\n",
    "* month,\n",
    "* day_of_week,\n",
    "* poutcome.\n",
    "\n",
    "Let's check what values they take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n",
      "admin.           8415\n",
      "blue-collar      7510\n",
      "technician       5443\n",
      "services         3227\n",
      "management       2386\n",
      "retired          1383\n",
      "entrepreneur     1187\n",
      "self-employed    1142\n",
      "housemaid         867\n",
      "unemployed        823\n",
      "student           720\n",
      "unknown           259\n",
      "Name: job, dtype: int64\n",
      "\n",
      "\n",
      "marital\n",
      "married     20220\n",
      "single       9357\n",
      "divorced     3721\n",
      "unknown        64\n",
      "Name: marital, dtype: int64\n",
      "\n",
      "\n",
      "education\n",
      "university.degree      9845\n",
      "high.school            7711\n",
      "basic.9y               4887\n",
      "professional.course    4231\n",
      "basic.4y               3372\n",
      "basic.6y               1869\n",
      "unknown                1430\n",
      "illiterate               17\n",
      "Name: education, dtype: int64\n",
      "\n",
      "\n",
      "default\n",
      "no         26415\n",
      "unknown     6944\n",
      "yes            3\n",
      "Name: default, dtype: int64\n",
      "\n",
      "\n",
      "housing\n",
      "yes        17503\n",
      "no         15040\n",
      "unknown      819\n",
      "Name: housing, dtype: int64\n",
      "\n",
      "\n",
      "loan\n",
      "no         27452\n",
      "yes         5091\n",
      "unknown      819\n",
      "Name: loan, dtype: int64\n",
      "\n",
      "\n",
      "contact\n",
      "cellular     21145\n",
      "telephone    12217\n",
      "Name: contact, dtype: int64\n",
      "\n",
      "\n",
      "month\n",
      "may    11266\n",
      "jul     5826\n",
      "aug     4970\n",
      "jun     4263\n",
      "nov     3311\n",
      "apr     2108\n",
      "oct      562\n",
      "sep      462\n",
      "mar      450\n",
      "dec      144\n",
      "Name: month, dtype: int64\n",
      "\n",
      "\n",
      "day_of_week\n",
      "thu    6964\n",
      "mon    6889\n",
      "wed    6578\n",
      "tue    6549\n",
      "fri    6382\n",
      "Name: day_of_week, dtype: int64\n",
      "\n",
      "\n",
      "poutcome\n",
      "nonexistent    28800\n",
      "failure         3469\n",
      "success         1093\n",
      "Name: poutcome, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.select_dtypes(exclude=['int64', 'float64']).columns:\n",
    "    print(col)\n",
    "    print(X_train[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'poutcome'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of columns to be transformed from string to categorical numeric objects\n",
    "str_cat_vars = X_train.select_dtypes(exclude=['int64', 'float64']).columns.values\n",
    "str_cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
       "       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a list of numeric columns to be scaled\n",
    "num_vars = X_train.select_dtypes(include=['int64', 'float64']).columns.values\n",
    "num_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Declare the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want the following steps to be processed in my preprocessing pipeline.\n",
    "1. Transform text variables into categorical numeric;\n",
    "2. Transform categorical variables into a set of binary variables (dummies, or one-hot encoded);\n",
    "3. Standardize continuous variables.\n",
    "\n",
    "**Note:** I treat variables of type `int64` as continuous. Sometimes, we want to treat such variables as categorical variables, so we then transform them into a set of dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I put these imports into the Setup section at the beginning\n",
    "# from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# encoder = OrdinalEncoder()\n",
    "# dummies = OneHotEncoder()\n",
    "\n",
    "dummy_pipeline = Pipeline([\n",
    "        ('encoder', OrdinalEncoder()),\n",
    "        ('dummies', OneHotEncoder()),\n",
    "    ])\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "prep_pipeline = ColumnTransformer([\n",
    "        (\"cat\", dummy_pipeline, str_cat_vars),\n",
    "        (\"num\", StandardScaler(), num_vars),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = prep_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.95603918,\n",
       "         0.77476545,  0.84745082],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.47320393,\n",
       "         0.774189  ,  0.84745082],\n",
       "       [ 1.        ,  0.        ,  0.        , ..., -1.23113588,\n",
       "        -1.36905844, -0.9393463 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.89107358,\n",
       "         0.71250867,  0.33357351],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -1.23113588,\n",
       "        -1.3373536 , -0.9393463 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -1.23113588,\n",
       "        -1.31717779, -0.9393463 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_prepared = prep_pipeline.transform(X_val)  # we do not *fit* the test data!\n",
    "X_test_prepared = prep_pipeline.transform(X_test)  # we do not *fit* the test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to build 2 binary classification models using any 2 of the following methods:\n",
    "1. Logistic Regression,\n",
    "2. Random Forest,\n",
    "3. GBM,\n",
    "4. Xgboost,\n",
    "5. Neural Network.\n",
    "\n",
    "Let's train the first four and see their performance and keep Nerual Nets as a cherry on a cake! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** I train the basic model in this section. I will tune hyperparameters later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "log_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we do on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105868952700678"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well we do on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163744267601834"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I leave model evaluation assessment on the test set for later analysis after I fine-tune the model with hyperparameters tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128675478823847"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128675478823847"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_mimebundle_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;34m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"text/plain\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"display\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'diagram'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text/html\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    277\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[1;32m--> 393\u001b[1;33m                                                 self._depth, level)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         return _safe_repr(object, context, maxlevels, level,\n\u001b[1;32m--> 170\u001b[1;33m                           changed_only=self._changed_only)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001b[0m\u001b[0;32m     99\u001b[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001b[0;32m    100\u001b[0m             \u001b[0mfiltered_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_score'"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'base_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    403\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__repr__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                             \u001b[1;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\lib\\pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[0;32m    277\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[1;34m(self, object)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0msio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_format\u001b[1;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[1;34m(self, object, context, level)\u001b[0m\n\u001b[0;32m    391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[1;32m--> 393\u001b[1;33m                                                 self._depth, level)\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         return _safe_repr(object, context, maxlevels, level,\n\u001b[1;32m--> 170\u001b[1;33m                           changed_only=self._changed_only)\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     def _pprint_estimator(self, object, stream, indent, allowance, context,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[1;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0mrecursive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchanged_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_pprint.py\u001b[0m in \u001b[0;36m_changed_params\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0minit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         if (repr(v) != repr(init_params[k]) and\n\u001b[0m\u001b[0;32m     99\u001b[0m                 not (is_scalar_nan(init_params[k]) and is_scalar_nan(v))):\n\u001b[0;32m    100\u001b[0m             \u001b[0mfiltered_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'base_score'"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "xgb_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING.** XGBClassifier gives errors when printing the output after `fit` method. It seems to be an issue with Scikit-Learn version 0.23.1 and higher, see discussion here: https://github.com/dmlc/xgboost/issues/5668\n",
    "\n",
    "I updated scikit-learn to version 0.23.2 and it still appears as an error..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597146454049518"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9174534664148908"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(X_val_prepared, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 Preliminary Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that *ALL* models overfit on the training set. The only exception is XGBClassifier.\n",
    "Therefore, we have to do some regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Regularization and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two classes in `Scikit-Learn` that help us tune hyperparameter:\n",
    "1. `GridSearchCV`, and\n",
    "2. `RandomizedSearchCV`.\n",
    "\n",
    "Let's try both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
